
# ArthaRaksha 



# About the Project
This project focuses on building a prototype resembling a Fraud Protection agent that can help ordinary citizens, especially those who are less aware and emerging digital users against scam calls and texts. Such people may include senior citizens, teenagers with recent digital bank accounts, people from rural parts becoming the emerging digital banking customer segment, people who are not very conversant with English or not so tech savvy etc. though recent reports suggest that well-informed individuals in senior private and public sector roles have also fallen for such frauds. This prototype Fraud Protection agent, named ArthaRaksha, is intended to be at the user’s service 24x7 in his / her native language through its mobile app version. The prototype is built using Vertex AI's Agent Builder and is powered by Google Cloud Platform and Google’s latest generative AI-based Large Language and Multi-modal languages such as Gemini 1.0 and Gemini 1.5 pro. The prototype can transcribe and translate native language speech and text, summarize events, identify the possibility of fraud, analyze a potential fraud, categorize as per RBI (Reserve Bank of India) fraud classification guidelines, and help generate incident reports of the potential fraud as per the inputs needed by cybercrime departments with pre-filled parameters (powered by Google’s Gen-AI LLM and MLM models underneath) and finally submit the fraud incident with just one ‘click’ through automated API integration with fraud reporting portal of agencies and also with banks (if applicable).

# Inspiration

The inspiration for this project came from personal experiences: 
In one case, one of the prototype developer’s aunt received a fraud call concerning her cousin with the ultimate intention to siphon off money. The caller claimed that the developer’s cousin was in trouble and demanded immediate payment for a supposed legal fee. Although the developer's aunt did not fall for the scam, the experience left a lasting impact on the family, highlighting the urgent need for effective fraud detection mechanisms.
In another incident, the other prototype developer’s mother received a fraudulent call from a bank that attempted to steal personal information under the garb of KYC renewal for an existing joint account. This joint account has the family’s lifelong savings linked to it.
When we researched further, we found a recent report by the Indian Cybercrime Coordination Centre in March 2024 outlining that the impact of digital financial frauds on direct individual banking users amounted to a staggering ₹40,000 crore over the last two years, that's approx. 4.8 Billion US Dollars. At the same time, the number of such fraud calls has grown by more than 110%. Cybercrime, especially financial fraud, poses a burgeoning and rapidly expanding threat in India, impacting millions of individuals and unsuspecting digital banking users. Many other countries and regions have also been experiencing a shocking boom of financial fraud related to digital banking.
This alarming situation underscored the increasing prevalence of phone scams and motivated us to develop a solution to help detect and mitigate such fraudulent activities. Generative-AI powered ArthaRaksha App prototype built upon the Google Cloud VertexAI Agent Builder platform is an attempt to demonstrate the possibility of complementing the relentless efforts of the Indian govt, RBI, and banking players in dealing with the herculean, rapidly mutating fraud patterns of scammers. With the collective efforts of all legitimate financial players in India, ArthaRaksha can be powered by a fraud detection and processing platform owned by RBI and contributed to by all the interested and legitimate banking players, telecom players etc. (similar to working models such as those powered by NPCI (UPI), NSDL (for ecommerce marketplace), Digilocker, or upcoming inter-operable payment system postulated by RBI). This way, such an underlying model can be continuously trained on the newest fraud data and patterns across languages and be up to date not only with the latest fraud detection patterns but also new fraud awareness protection, response, and control mechanisms developed by both RBI / Govt agencies and banking and other financial players.
Customized versions of the App can be built and deployed by legitimate financial institutions such as banks whereas the underlying platform, data, and model may be contributed to by all financial players, RBI, and Government financial and cybercrime detection agencies. The app intends to bridge the gap between the genuine, dedicated, and independent initiatives by law enforcement agencies, RBI, banks etc. and their adoption as part of a banking user’s daily life. Adoption is best when the interaction with sophisticated backends is hidden or invisible to make it a layman’s app in the user’s hand-held device.
Financial fraud methods are similar to viruses and follow viral evolution patterns - they mutate fast and if the protection system is not time-sensitive and agile enough to learn and respond, the damage is already done at a mammoth scale by the time users realize that they have been conned and agencies get a hold of fraud methods. The ability envisioned through the solution is to embed a much needed “real-time”, trusted analysis capabilities for fraud call and text content empowering users with an immediate warning (in some cases, even before a fraud call is over) and to drastically improve the reaction times of the protection, control, and reporting systems in place.


# What it does
Generative AI-powered Arth Raksha application prototype built upon the Google Cloud Vertex AI agent builder platform and powered by Google's large language models is an attempt to demonstrate the possibility of complementing the relentless efforts of the government of India, Reserve Bank of India and the legitimate banking players in dealing with a Herculean rapidly mutating fraud patterns of scammers. Backed by powerful generative AI models and collective effort of all legitimate financial players and government authorities in India, Arth Raksha can be continuously trained on newest fraud data and patterns collected by the agencies and the banks and then can be positioned well to provide an intuitive 24/7 available service to every digital banking user in his own native language, helping him through the life cycle of a fraud incident including awareness, early detection and prevention, understanding and analysis of possible fraud, and reporting fraud incidents automatically in real-time.
 
In case the fraud poses risks, it is directly to the authorities with virtually no effort. The audio call that you are now going to hear, though simulated bears a strong resemblance to millions of similar calls that have been ruining the lives and the finances of digital banking users and citizens of India on a daily basis. Of course, the prototype can be scaled at a global level.

# How we built it
Step 1: Research and Data Collection
The first step involved extensive research into the characteristics of fraud calls. We collected data from various sources, including publicly available datasets of scam call recordings and transcripts. Below are example datasets that were used:
●	RBI published publicly available documents were used to benchmark category of frauds
○	< https://www.rbi.org.in/financialeducation/RajuandATM.aspx>
●	A BigQuery scam call dataset was used that was publicly available:
○	<https://github.com/7shiny786/ArthaRaksha/blob/main/Data/ScamCalls_SM_Scam%20Call_1.mp3 >
●	Few audio calls simulating real fraud calls were made - they are available in github as example calls and used in the prototype flow. Bank / ecommerce clients' names that were used to make the call look real scam calls made by scammers. These are not real scam calls and has no relation with the bank name or ecommerce company name taken in the scam calls.
○	<https://github.com/7shiny786/ArthaRaksha/blob/main/Data/ScamCalls_SM_Scam%20Call_2.mp3 >

Since the RBI document was a collection of text, images, text blended within images, and a lot of custom formatting that is commonly seen in marketing materials, OCR was used to extract useful context related to fraud examples and their categories and the processed document was used as input as a data store for grounding.
	
Step 2: Designing the Architecture
We designed the system architecture on the Google Cloud platform and integrated different Google Cloud services to bring the solution to life. A schematic representation of the technical architecture is attached  <here > to enable readers to easily correlate with the below explanation. 
The architecture includes:
●	Data Ingestion and storage: Google Cloud storage has been used as the predominant data storage component.
○	Call (audio) record file are stored at -	<https://github.com/7shiny786/ArthaRaksha/blob/main/Data/ScamCalls_SM_Scam%20Call_2.mp3 >
○	Scam documents including text files and transcribes are stored at -	<https://github.com/7shiny786/ArthaRaksha/blob/main/Data/transcripts_SM_Scam%20Call_1_transcript_66553c59-0000-222f-8ea3-582429cdbdc8.json>
○	VertexAI Agent Builder used tool Datastore for the purpose of retrieving data chunks (called snippets) when requested to be grounded to specific datasets for certain questions (for example, fraud categorization). The underlying storage for Datastore is google cloud storage. The cleansed RBI guideline is stored at - <https://github.com/7shiny786/ArthaRaksha/blob/main/Data/RBIDoc_DataStore.docx>
○	Staging area has been used to store temporary files generated as part of the conversation flow. This serves as kind of working memory for the application for a specific session. 


Application Stack:
Front-end: The user interface part is simple, intuitive, and currently built and deployed over Slack (link is available <here> and access can be provided on request. This is the point at which the user will interface with ArthaRaksha and the current implementation, which is only a prototype, may be replaced with interfaces built over open-source frameworks such as Vue.JS (vue-chatbot), Reach.JS (with chatfuel), RASA etc. Alternatively, one may choose to opt for managed services meant for developers such as Communicate, Microsoft Bot, Botanic or those integrated with ready-to-use customer-facing agents that have already realized massive adoption such as Whatsapp, Telegram, Facebook Messenger or Google’s Dialog Flow’. There are immense opportunities to differentiate an Artharaksha offering in the front-end and financial players such as banks or authorized fraud protection partners of RBI / Government may like to integrate ArthaRaksha’s capabilities through existing applications and even monetize it.
Back-end: This is the layer that is currently being showcased through the Vanilla App’s Slack interface. The Backend has multiple stages. The hub of the backend is a mesh of Agents built upon Google's Vertex AI Agent Builder Platform. There are multiple agents that together encompass the back-end solution. These include:
Anchor/greeting Agent: “ArathaRaksha-We care” This agent is supposed to be a single messenger for the user. It greets the user, takes questions from the user and redirects the user to the specialist agents based on the user’s intent (or ask) and topic of interest and responds back to the user.
There are two specialist Agents:
“Speech_to_Text_Agent_SM”: user requests related to transcription and translation are received and processed and responded to by this agent. This agent can also do a handover to the next agent if need be.
“Fraud_Analysis_Agent”: user requests related to fraud detection, analysis, chronology summarization, and automatic incident reporting are processed and responded to by this agent.
Agents are prompt engineered and built on top of Google’s Gemini 1.0 Generative AI model. This is the latest gen-AI model supported by VertexAI Agent Builder at the time of writing this article.
Agents use tools to accomplish tasks. There are 3 types of tools available currently in the Vertex AI Agent Builder platform - OpenAPI, DataStore, and Function. Tools are used in the following way:


OpenAPI type Tools such as “transcription_sm”, “translation_sm”, and “summarize_sm” are used to trigger Google’s latest Gen-AI model, Gemini 1.5 pro available through APIs in vertex AI Model Garden. Reasons to choose this API include the model’s better performance compared to other models tested and its best-in-class multi-modal capabilities that were surprisingly pleasing and accurate and could be leveraged for multi-tasking. Tools such as “read_translation_sm” were used in conjunction with “summarize_sm” to circumvent challenges around parameter passing beyond one agent hop as specifying system and session parameters for making calls doesn’t seem to be possible at the moment in the current version of VertexAI Agent builder. 
Datastore type Tools such as “Fraud_category” have been used to for grounding to enable retrieval of the most relevant information. Snippets from the vertex AI Datastore that host the processed and chunked RBI fraud guideline and category document are retrieved and synthesized by Vertex AI agent to respond to user queries. Agents have been prompted to ensure that any question that needs fraud categorization as a direct or indirect response must use the Datastore to respond to such a question as public fraud categorization knowledge of GenAI models may vary and may not have correct specialization as seen during testing. Built on top of Vertex AI Search, that is Google’s go-to-market RAG method implementation, Vertex AI Data Store tool is found to be working as an out-of-the-box grounding system and supports RAG (or retrieval augmented generation) APIs for document layout processing, ranking, retrieval, and performing checks on grounding outputs to private trusted enterprise data such as Cybercrime databases and, in this prototype, is limited to grounding against the RBI document guidelines for fraud category. The idea is to demonstrate the grounding part that is critical to make the model more accurate, specialized, unadulterated, regulated, governed, and trusted and at the same time remain contextually relevant and provide a high level of accuracy in fraud analytics by using only trusted, approved data. In the real world, such fraud detection and analytics gen-AI models must be regularly fine-tuned and need working memory for RAG implementation ( for details, read: TransfromerFAM research paper by Google). Such activities have not been performed in this prototype building exercise but is highly recommended provided access to diverse, verified fraud data (both structured and unstructured) is feasible- this is where we have struggled as one may expect.
Function type Tools such as the “Fraud_Reporting_API_SM” tool is supposed to be called by calling agent such as anchor of fraud analysis agent to use all the parameter variables captured through the transcribed translation and fraud analysis, add system parameters that should already be available to authorized installed app agent (such as event time, sender and receiver details, user_id, user’s location etc.) and then use all these inputs to create a JSON / YAML structure that can be used to automatically submit fraud incident to cyber crime reporting portals through cloud services such as Google Apigee. This part could not be completed as getting API access to such portals has not been possible until the time of writing this article. However, it is built into the technical LLD to showcase the completion of the idea. The Agent is supposed to receive a Request_ID in response to the submission of the fraud incident through the “Fraud_Reporting_API_SM”  tool and share the same with the user and with that, an initial fraud-related user conversation should conclude.
Generative AI Models available in Model Garden or open-source models outside Google Cloud cannot be accessed directly from VertexAI Agent Builder platform components at the moment. Therefore, second-generation Google Cloud Functions deployed on serverless Google Cloud Run have been used to accomplish the integration with Google Cloud internal systems such as Gemini 1.5 Pro multi-modal model available in vertex AI Model Garden.
Integration beyond GCP: Proposed integration with other Applications such as those of Crime Bureau, RBI or Financial Bank’s internal or customer-facing applications hosted in any other cloud or on-prem may be accomplished through Google’s extended ecosystem consisting of Pub/Sub and Apigee. Pub/Sub can be used as a message broker to decouple publishing agents (emitted from the Vertex AI chat interface) from the subscribing agents such as the 3rd party SAAS applications, database and servers thereby providing massive asynchronous parallel processing that will anyways be needed to scale the application in the future. Whereas, Apigee Platform (Apigee X or Apigee hybrid) may be used to expose REST APIs for publishers to publish messages to Pub/Sub topics and Async APIs (Websockets) that can be “consumed” by “Subscribers” without exposing internal ecosystem of the fraud analysis platform. These extensions are currently proposed but not built in as part of the prototype and may be taken up in the future. Cloud Run may host services that perform “Pub/Sub to Websockets” translation wherever needed to provide integration with legacy services.


Step 3: Implementation and Testing
After deploying the Agent Builder, we integrated it with Slack which could alert users when a call is suspected to be fraudulent. An event-driven architecture may be used to raise an alert to the user even in the middle of a call warning him of a potential scam and giving the option to the user to continue the call or disconnect. Such alerts can go a long way in putting up a real-time fraud prevention shield thereby preventing possible damage before it's done. While we have conducted testing to ensure the system's reliability, accuracy and reproducibility, readers and developers are advised to adapt the work and improve upon it by adding more examples for the agents, adding more quality enriched data, and extending API exposing services as proposed above for 3rd party integration to general SAAS application and making adjustments as necessary based on outcome and performance.


Special considerations for security and privacy need to be made including at a data level (for example creating contextual custom filters for inputs to LLMs and LLM responses) and access levels. The level of filtering, that is safety settings, for LLM responses has been set at “BLOCK_ONLY_HIGH” rather than the default “BLOCK_MEDIUM_AND_ABOVE” for the following types:
Harassment
Hate speech
Sexually explicit
Dangerous
This has been done since we observed that Gemini 1.5 pro sometimes failed to process requests when the input content was detected to be unsafe with the default settings. In the specific case of fraud, we may expect that transcribed and translated content may have a higher-than-expected level of generally acceptable content. In real-world situations, custom safety filters need to be applied at input and processing levels to avoid filtering out ‘unsafe’ content while putting a different set of filters for output depending on whether the LLM is supposed to return original transcripts/translations or during the time it needs to summarize or draw conclusions regarding the events that unfolded in the scammer’s conversation with the receiver.


# Challenges Faced

Developing ArthaRaksha presented several challenges, primarily stemming from the intricate nature of fraud detection and the need for robust, adaptable AI solutions:
Agent Builder:
Agent Context Passing: Ensuring seamless context passing between different components of the agent was critical for accurate analysis and decision-making. This involved developing strategies to effectively store and retrieve context across stages, such as the initial call transcription, translation, and subsequent fraud analysis steps. 
We found that VertexAI Agent builder lacks a developer-managed and controlled way to pass and invoke session and context parameters as well as custom parameters unlike the more structured way built to call or invoke agents and tools. We are aware that such functionalities are available in Google’s DialogFlow offering. We hope that a 3rd option related to structured parameter passing becomes easier to implement and use.
Agent Prompt Engineering & Fine-Tuning: Training the agent builder on diverse datasets and real-world fraud scenarios proved challenging. Adapting the model to recognize subtle variations in fraud patterns and evolving scammer tactics required continuous learning and fine-tuning. 
Agent Scalability: Ensuring that the agent could handle a high volume of incoming calls and maintain responsiveness without compromising performance was a significant consideration. We really missed features such as 
the ability to redo a particular user request during iterative testing,
One-click deployment and addition of a multi-agent example workflow across agents that was successfully accomplished- making it easier to save examples.
Better logging and tracing (especially end-to-end session tracing) for the paths taken by agents before responding, 
We found it difficult to trace the stored variable states and user parameters as well as agent and tool invocation points during handovers- the troubleshooting for prompt engineering turned out to be a tedious job as it involved a lot of permutations and combinations based on assumptions- there is an opportunity to minimize the effort involved here for development if the developer can trace the chain of actions and corresponding state variables that the different components in the workflow are actually taking.
Out of box Prompt versioning and templatization, especially for nested prompts, capabilities can be improved as prompt engineering is a mix of art and logic and therefore needs multiple rounds of repetitive iterations before desirable outcome is realized - this is effort intensive and therefore is an area of opportunity to improve developer experience. Restoring previous versions of prompt templates and tracking changes can be improved.
An aspiration feature is to enable developers to use a Like/Dislike button at the end of every Agent Response during prompt engineering and implement in the backend as a continuous reinforcement learning loop with human feedback (RLHF). We couldn’t find this feature.
Though Vertex AI Agent Builder DataStore tool powered by vertex AI Search is phenomenal when it comes to grounding as it supports different types of structured and unstructured data, allows OCR-based methods to extract information, and provides out of box capabilities for chunking, a direct integration with Langchain or LlamaIndex based retrieval mechanisms from Google’s or 3rd Party Vector DB’s is a feature that we found to be missing. In a real world scenario, it is quite possible that the data store for grounding may not be a data store hosted in the internal environment but a common vector DB hosted on a different platform co-owned and governed by someone else. In this case it may be Govt and RBI and contributed to by different authorized private and public sector entities such as banks and telecom companies.
Vertex AI agent components are currently not able to directly integrate with the rest of the Google cloud services unless they go through a JSON based OpenAPI tool type integration through a Google Cloud Function. More seamless integration options can certainly be built-in to allow invoking a diverse set of Google cloud platform services directly from the prompts or through tools, (preferably text to code tools) as we may expect there will be a much larger spread of existing critical legacy services that will continue to exist alongside and need structured REST / socket based API integration prerequisites.


Data Privacy: Maintaining user privacy and protecting sensitive information is of paramount concern. Invocation of services such as DLP should be enabled out of the box both for private data detection and obfuscation to make the environment even more developer friendly. We must remember that both the possibility of sensitive and private data creeping into data and the probability of such instances being overlooked or missed are higher in scenarios where unstructured data in the form of audio, images, native language text, video, and pdf documents are involved. No sensitive data has been used as input for the current prototype.


Security & Role based access control: Different levels of Role based Access Controls are needed at the Developer level, the user level for the front-end (ex. Slack or DialogFlow), at the API integration level (mostly through service accounts) and data access level (again currently implemented through service account). The integration of VertexAI Agent builder with Dataplex may go a long way to bring uniformity and consistency of authorizing or restricting access to underlying data be it through Vertex AI Data Store (or Vertex AI Search), vector DB’s or Data lakes / Data Meshes. Such integration and role allocation will significantly fast-track projects due to ease of applying or revoking such permission by the platform administrators and guaranteed consistency from Data Governance perspective. At the end, all LLM Models, Model building platforms, and Gen-AI apps are consumers of data and need to be treated at par with human users, other traditional applications, and existing system users such as ML Models and analytics dashboards.  


API Integration with Third-Party Systems through Apigee may be brought in as an out of box functionality to provide seamless integration with external APIs (in this case, banking systems, cybercrime departments, and other relevant entities was crucial for automated incident reporting and response). Managing API keys and secret credentials, handling authentication, and ensuring data consistency across systems presented challenges.


Multilingual Support: Developing a system that effectively recognizes and processes various Indian languages posed a significant challenge. Translating and understanding diverse dialects and accents required advanced natural language processing techniques. Recognizing and adapting to culturally specific fraud tactics and communication styles was essential to ensure the system's effectiveness across diverse demographics. 


Compliance Reporting and Auditing: Auditing the conversation life-cycle with LLM and LLM processing and response patterns need to be made more robust to meet the following requirements:
Auditing capabilities should automatically generate reporting metrics related to Model usage, performance, accuracy, and metrics that need to be auto-reported by ArthaRaksha platform for legal and regulatory compliance as well as ethical guardrails related to Responsible AI
As a subset of compliance, LLM explainability should be built into Vertex AI Agent builder Platform that will not only help developers and product managers offer a strong value proposition for model adoption but also help build the next level trust Generative AI technology and models meet complex and sensitive subjects such as fraud. This is critical for all parties involved in the ecosystem - Government, Regulatory bodies like RBI in this case, public and private financial entities, ecosystem partners (ex. Fraud insurance providers and technology partners, cloud service providers etc.), law enforcement agencies, and, lastly, the general public.


# Accomplishments that we're proud of
Outcome Achieved:
We successfully developed a prototype for a 24/7 fraud protection agent, ArthaRaksha, that is demonstrated to be capable of 
Transcribing and translating audio records and text (in multiple languages) with the context of fraud
Analyzing possibility of a call or text being a fraud attempt
Providing explanations to the user based on natural language Q&A
Summarizing the chronology of events with regard to the calls
Spreading awareness about fraud to mass users at a personalized level
Identifying the category of fraud in line with RBI fraud category guidelines
Sharing and recommending best practices at a personalized level based on user’s recent experiences
Assisting users to gauge the risk level of the situation the user is in and help him with inputs on personal information that the user might have shared inadvertently during the course of the call and the possible ramifications of the same
Detecting and building the ability to auto-report fraud incidents on behalf of the user by not only self-populating the mandatory inputs but also providing detailed evidence of the potential financial fraud attempt from the model’s context. 

Technology Experience honed:

Explored and used latest and cutting edge Large Language and multi-modal models from Google Cloud Platform and easy to adopt platform for building gen AI agent using vertex AI Agent Builder 

Potential social Impact:

We were able to give aspirational shape and form to an idea to counter financial scams and were able to build a strong foundation for a self-evolving ecosystem that can be fed and nurtured through collaboration and contribution of all players and institutions interested in the fight against financial fraud. The project has demonstrated the feasibility of a federated shared data and AI platform paving the way for a more coordinated and comprehensive approach to combating financial crime.

# What we learned

Throughout the project, we gained invaluable insights and skills:
Understanding of Fraud Tactics and Response systems in place: Most common tactics used by fraudsters, understanding their methods, channels and psychological ploys to deceive victims.


Understanding of Fraud protection initiatives: This includes RBI campaigns, crime registration rules, policies, banks and telecom company initiatives to curb fraud cases, and processes to raise fraud incidents.


Google Cloud’s Vertex AI: We became proficient in using Vertex AI's Agent Builder integrating it with other Google Cloud services such as Cloud Function, Cloud Run, and Gemini 1.5 pro model available in VertexAI Model Garden. Learnings also include building, using, and integrating VertexAI data stores (powered by VertexAI Search), Ready-to-use synchronous and asynchronous API calls using Google Cloud API services such as Speech to text and translation services, and more.


Prompt Engineering and grounding: Prompt engineering for complex scenarios needs a structured logical approach to problem-solving and works best with robust fully functional examples. We also realized that a fine-tuned and grounded model is best suited to avoid hallucinations and model distractions. The underlying quality and richness of the data used for grounding is a key make-or-break factor for such use cases that need to deal with highly unstructured and unexpected data patterns.


Gen-AI-based developer empowerment: Gen-AI capabilities are still evolving but even at their current state of maturity, we learned that technology can significantly fast-track complex Data and AI development projects. They can empower technologies with business acumen and Business analysts with technology acumen thereby blurring the lines of traditional core competence and areas of expertise between business and technology. Gen-AI supported by a robust ecosystem of data, application, and integration capabilities, can rapidly increase the proportion of AI investment and projects that lead to real, positive Business ROI  (and real NPV realizations), but more importantly, it can have a real, positive social impact on using technology for the genuine welfare of people.


Promises, Limitations and Opportunities: We learned that Vertex AI Agent Builder can become a game changer in driving massive adoption of complex technology offerings through an intuitive, simple human interface and natural language-based user interactions. Through the development experience, we also came across limitations of the current version of Vertex AI Agent Builder that, we understand, is in a preview state at the time of writing this document. We expect the platform to naturally evolve through further testing and improvements to become even more helpful to developers and churn massively impacting Gen-AI apps. Some of the limitations are discussed in the section “Challenges faced”. We also have tremendous opportunities in extending VertexAI Agent Builders to become part of the larger integrated ecosystem that comprises an enormous spread of traditional tech stack, applications, and data systems (such as data warehouses and data lakes).

# What's next for ArthaRaksha:-
Further development of the ArthaRaksha prototype to enhance its accuracy and capabilities. This includes expanding the training data, optimizing the AI models, and incorporating feedback from real-world users.
Exploring partnerships with banks and financial institutions to integrate ArthaRaksha into their existing fraud prevention systems. This would allow for wider adoption and a more proactive approach to fraud detection and mitigation.
Collaborating with government agencies and regulatory bodies, such as the Reserve Bank of India (RBI) and the Indian Cybercrime Coordination Centre, to develop a more comprehensive and collaborative framework for combatting financial fraud. This could involve sharing data, best practices, and resources to create a more robust and effective ecosystem for fraud prevention.
Expanding the reach of ArthaRaksha beyond India to other countries facing similar challenges with financial fraud. This would require tailoring the solution to local languages and regulatory environments.
Continuous research and development to stay ahead of evolving fraud tactics and technologies. This includes exploring new AI models, data sources, and methodologies to ensure the effectiveness of ArthaRaksha in the long term.

ArthaRaksha can be installed on mobile which will tell real-time in ongoing calls if the call is fraud or not. This will help users protect themselves from Fraud.


# Conclusion
This project was both a personal and professional journey. Inspired by a real-life incident, We were motivated to leverage advanced Vertex AI technologies to address a growing concern. Through this project, we not only honed our technical skills but also contributed to a cause that could potentially protect others from falling victim to fraud. The challenges faced along the way were valuable learning experiences, shaping our understanding of Vertex AI applications and their impact on society.


